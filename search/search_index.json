{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"data-api-template Purpose The objective of this project is to provide a standard template for creating a data API. It includes: The procedure for building a Postgres SQL database on Azure and procedure for importing data. A machine learning model including pytest quality tests and mlflow tracking on azure An API (FastAPI) with token-based authentication and Ml-ops Monitoring A Streamlit dashboard to expose Ml-ops Monitoring Dependencies: poetry azure CLI azure ml CLI psql Setup Create virtual environement and install requierements: poetry install Create .env file using env_template.txt To create the Olist database, execute these commands: chmod +x ./database/azure_postgres/create_postgres.sh ./database/azure_postgres/create_postgres.sh chmod +x ./database/azure_postgres/create_tables.sh ./database/azure_postgres/create_tables.sh chmod +x ./database/azure_postgres/import_postgres.sh ./database/azure_postgres/import_postgres.sh You can execute tests to make sure the setup is good: pytest Train a new model You can update training functions and then use ./model/train.sh to train a new model. (Don't forget to change run_name) Launch the API Get your token: poetry run python -m api.utils Update model_name in ./api/launch_app.sh and then you can execute it Use Streamlit ML-OPS Dashboard Execute this command poetry run streamlit run ml_ops/dashboard.py","title":"Accueil"},{"location":"#data-api-template","text":"","title":"data-api-template"},{"location":"#purpose","text":"The objective of this project is to provide a standard template for creating a data API. It includes: The procedure for building a Postgres SQL database on Azure and procedure for importing data. A machine learning model including pytest quality tests and mlflow tracking on azure An API (FastAPI) with token-based authentication and Ml-ops Monitoring A Streamlit dashboard to expose Ml-ops Monitoring","title":"Purpose"},{"location":"#dependencies","text":"poetry azure CLI azure ml CLI psql","title":"Dependencies:"},{"location":"#setup","text":"Create virtual environement and install requierements: poetry install Create .env file using env_template.txt To create the Olist database, execute these commands: chmod +x ./database/azure_postgres/create_postgres.sh ./database/azure_postgres/create_postgres.sh chmod +x ./database/azure_postgres/create_tables.sh ./database/azure_postgres/create_tables.sh chmod +x ./database/azure_postgres/import_postgres.sh ./database/azure_postgres/import_postgres.sh You can execute tests to make sure the setup is good: pytest","title":"Setup"},{"location":"#train-a-new-model","text":"You can update training functions and then use ./model/train.sh to train a new model. (Don't forget to change run_name)","title":"Train a new model"},{"location":"#launch-the-api","text":"Get your token: poetry run python -m api.utils Update model_name in ./api/launch_app.sh and then you can execute it","title":"Launch the API"},{"location":"#use-streamlit-ml-ops-dashboard","text":"Execute this command poetry run streamlit run ml_ops/dashboard.py","title":"Use Streamlit ML-OPS Dashboard"},{"location":"api/database_utils/","text":"Base Bases: DeclarativeBase Base class for SQLAlchemy ORM models. Source code in api/database.py class Base(DeclarativeBase): \"\"\"Base class for SQLAlchemy ORM models.\"\"\" pass DBpredictions Bases: Base ORM model for the 'predictions' table. Attributes: prediction_id ( str ) \u2013 Primary key, unique identifier for the prediction. timestamp ( str ) \u2013 Timestamp of the prediction. produit_recu ( int ) \u2013 Quantity of the received product. temps_livraison ( int ) \u2013 Delivery time. prediction ( int ) \u2013 The prediction value. model ( str ) \u2013 The model used for the prediction. Source code in api/database.py class DBpredictions(Base): \"\"\" ORM model for the 'predictions' table. Attributes: prediction_id (str): Primary key, unique identifier for the prediction. timestamp (str): Timestamp of the prediction. produit_recu (int): Quantity of the received product. temps_livraison (int): Delivery time. prediction (int): The prediction value. model (str): The model used for the prediction. \"\"\" __tablename__ = \"predictions\" prediction_id: Mapped[str] = mapped_column(primary_key=True, index=True) timestamp: Mapped[str] produit_recu: Mapped[int] temps_livraison: Mapped[int] prediction: Mapped[int] model: Mapped[str] connect_to_postgres() Connect to a PostgreSQL database using environment variables. Returns: engine \u2013 SQLAlchemy engine instance for the PostgreSQL connection. Source code in api/database.py def connect_to_postgres(): \"\"\" Connect to a PostgreSQL database using environment variables. Returns: engine: SQLAlchemy engine instance for the PostgreSQL connection. \"\"\" load_dotenv() # Define your PostgreSQL connection parameters hostname = os.environ.get(\"SERVER\") database = os.environ.get(\"DATABASE\") username = os.environ.get(\"POSTGRES_USER\") password = os.environ.get(\"PASSWORD\") # Create a connection to the PostgreSQL database connection_string = f\"postgresql://{username}:{password}@{hostname}/{database}\" print(connection_string) engine = create_engine(connection_string) print(engine) return engine create_db_prediction(prediction, session) Create a new prediction record in the database. Parameters: prediction ( dict ) \u2013 A dictionary containing prediction details. session ( Session ) \u2013 SQLAlchemy session object. Returns: DBpredictions ( DBpredictions ) \u2013 The newly created DBpredictions object. Source code in api/database.py def create_db_prediction(prediction: dict, session: Session) -> DBpredictions: \"\"\" Create a new prediction record in the database. Args: prediction (dict): A dictionary containing prediction details. session (Session): SQLAlchemy session object. Returns: DBpredictions: The newly created DBpredictions object. \"\"\" db_prediction = DBpredictions(**prediction, prediction_id=generate_id()) session.add(db_prediction) session.commit() session.refresh(db_prediction) return db_prediction generate_id() Generate a unique string ID. Returns: str \u2013 A randomly generated unique string ID. Source code in api/database.py def generate_id(): \"\"\" Generate a unique string ID. Returns: str: A randomly generated unique string ID. \"\"\" length = 14 characters = string.ascii_letters + string.digits return ''.join(random.choice(characters) for i in range(length)) get_db() Dependency to get the database session. Yields: Session \u2013 SQLAlchemy database session. Source code in api/database.py def get_db(): \"\"\" Dependency to get the database session. Yields: Session: SQLAlchemy database session. \"\"\" engine = connect_to_postgres() session_local = sessionmaker(autocommit=False, autoflush=False, bind=engine) Base.metadata.create_all(bind=engine) database = session_local() try: yield database finally: database.close()","title":"Database Utils"},{"location":"api/database_utils/#api.database.Base","text":"Bases: DeclarativeBase Base class for SQLAlchemy ORM models. Source code in api/database.py class Base(DeclarativeBase): \"\"\"Base class for SQLAlchemy ORM models.\"\"\" pass","title":"Base"},{"location":"api/database_utils/#api.database.DBpredictions","text":"Bases: Base ORM model for the 'predictions' table. Attributes: prediction_id ( str ) \u2013 Primary key, unique identifier for the prediction. timestamp ( str ) \u2013 Timestamp of the prediction. produit_recu ( int ) \u2013 Quantity of the received product. temps_livraison ( int ) \u2013 Delivery time. prediction ( int ) \u2013 The prediction value. model ( str ) \u2013 The model used for the prediction. Source code in api/database.py class DBpredictions(Base): \"\"\" ORM model for the 'predictions' table. Attributes: prediction_id (str): Primary key, unique identifier for the prediction. timestamp (str): Timestamp of the prediction. produit_recu (int): Quantity of the received product. temps_livraison (int): Delivery time. prediction (int): The prediction value. model (str): The model used for the prediction. \"\"\" __tablename__ = \"predictions\" prediction_id: Mapped[str] = mapped_column(primary_key=True, index=True) timestamp: Mapped[str] produit_recu: Mapped[int] temps_livraison: Mapped[int] prediction: Mapped[int] model: Mapped[str]","title":"DBpredictions"},{"location":"api/database_utils/#api.database.connect_to_postgres","text":"Connect to a PostgreSQL database using environment variables. Returns: engine \u2013 SQLAlchemy engine instance for the PostgreSQL connection. Source code in api/database.py def connect_to_postgres(): \"\"\" Connect to a PostgreSQL database using environment variables. Returns: engine: SQLAlchemy engine instance for the PostgreSQL connection. \"\"\" load_dotenv() # Define your PostgreSQL connection parameters hostname = os.environ.get(\"SERVER\") database = os.environ.get(\"DATABASE\") username = os.environ.get(\"POSTGRES_USER\") password = os.environ.get(\"PASSWORD\") # Create a connection to the PostgreSQL database connection_string = f\"postgresql://{username}:{password}@{hostname}/{database}\" print(connection_string) engine = create_engine(connection_string) print(engine) return engine","title":"connect_to_postgres"},{"location":"api/database_utils/#api.database.create_db_prediction","text":"Create a new prediction record in the database. Parameters: prediction ( dict ) \u2013 A dictionary containing prediction details. session ( Session ) \u2013 SQLAlchemy session object. Returns: DBpredictions ( DBpredictions ) \u2013 The newly created DBpredictions object. Source code in api/database.py def create_db_prediction(prediction: dict, session: Session) -> DBpredictions: \"\"\" Create a new prediction record in the database. Args: prediction (dict): A dictionary containing prediction details. session (Session): SQLAlchemy session object. Returns: DBpredictions: The newly created DBpredictions object. \"\"\" db_prediction = DBpredictions(**prediction, prediction_id=generate_id()) session.add(db_prediction) session.commit() session.refresh(db_prediction) return db_prediction","title":"create_db_prediction"},{"location":"api/database_utils/#api.database.generate_id","text":"Generate a unique string ID. Returns: str \u2013 A randomly generated unique string ID. Source code in api/database.py def generate_id(): \"\"\" Generate a unique string ID. Returns: str: A randomly generated unique string ID. \"\"\" length = 14 characters = string.ascii_letters + string.digits return ''.join(random.choice(characters) for i in range(length))","title":"generate_id"},{"location":"api/database_utils/#api.database.get_db","text":"Dependency to get the database session. Yields: Session \u2013 SQLAlchemy database session. Source code in api/database.py def get_db(): \"\"\" Dependency to get the database session. Yields: Session: SQLAlchemy database session. \"\"\" engine = connect_to_postgres() session_local = sessionmaker(autocommit=False, autoflush=False, bind=engine) Base.metadata.create_all(bind=engine) database = session_local() try: yield database finally: database.close()","title":"get_db"},{"location":"api/introduction/","text":"Documentation API Introduction This API aims to expose a machine learning model. It contains a single endpoint allowing a prediction to be made from the explanatory variables. It includes token-based authentication. Code Structure main.py : The entry point of the API application. It initializes the FastAPI application, sets up routing, and may include logic for starting the server. predict.py : Contains the logic for making predictions with the machine learning model. It likely defines FastAPI endpoints to receive prediction requests and return the results. opentelemetry_setup.py : Configures OpenTelemetry for monitoring and tracing the application. It helps in collecting metrics and traces for monitoring and debugging. utils.py : Contains utility functions used across the API application. This may include authentication logic, helpers for data processing, etc. database.py : contains the logic for connecting to and interacting with the database. It may include functions for creating database sessions, data models, and CRUD operations model_loader.py : contains the logic for loading the machine learning model from a file or external source. It's used to prepare the model for predictions. launch_app.sh : A shell script used to launch the API application. It checks if the machine learning model is loaded and, if not, runs a script to load it before starting the API with Uvicorn. Authentification You need a token to use the predict endpoint of the api. To get this token you need to call the generate_token(\"admin\") function in the api/utils.py file python3 -m api.utils Endpoints Prediction URL : /predict Method : POST Authentication required : Yes Request body : Model-specific data for prediction. Response : Prediction result.","title":"Introduction"},{"location":"api/introduction/#documentation-api","text":"","title":"Documentation API"},{"location":"api/introduction/#introduction","text":"This API aims to expose a machine learning model. It contains a single endpoint allowing a prediction to be made from the explanatory variables. It includes token-based authentication.","title":"Introduction"},{"location":"api/introduction/#code-structure","text":"main.py : The entry point of the API application. It initializes the FastAPI application, sets up routing, and may include logic for starting the server. predict.py : Contains the logic for making predictions with the machine learning model. It likely defines FastAPI endpoints to receive prediction requests and return the results. opentelemetry_setup.py : Configures OpenTelemetry for monitoring and tracing the application. It helps in collecting metrics and traces for monitoring and debugging. utils.py : Contains utility functions used across the API application. This may include authentication logic, helpers for data processing, etc. database.py : contains the logic for connecting to and interacting with the database. It may include functions for creating database sessions, data models, and CRUD operations model_loader.py : contains the logic for loading the machine learning model from a file or external source. It's used to prepare the model for predictions. launch_app.sh : A shell script used to launch the API application. It checks if the machine learning model is loaded and, if not, runs a script to load it before starting the API with Uvicorn.","title":"Code Structure"},{"location":"api/introduction/#authentification","text":"You need a token to use the predict endpoint of the api. To get this token you need to call the generate_token(\"admin\") function in the api/utils.py file python3 -m api.utils","title":"Authentification"},{"location":"api/introduction/#endpoints","text":"","title":"Endpoints"},{"location":"api/introduction/#prediction","text":"URL : /predict Method : POST Authentication required : Yes Request body : Model-specific data for prediction. Response : Prediction result.","title":"Prediction"},{"location":"api/utils/","text":"SinglePredictionInput Bases: BaseModel Model for single prediction input. Attributes: produit_recu ( int ) \u2013 The quantity of the received product. temps_livraison ( int ) \u2013 The delivery time. Source code in api/utils.py class SinglePredictionInput(BaseModel): \"\"\" Model for single prediction input. Attributes: produit_recu (int): The quantity of the received product. temps_livraison (int): The delivery time. \"\"\" produit_recu: int temps_livraison: int SinglePredictionOutput Bases: BaseModel Model for single prediction output. Attributes: prediction ( int ) \u2013 The predicted value. Source code in api/utils.py class SinglePredictionOutput(BaseModel): \"\"\" Model for single prediction output. Attributes: prediction (int): The predicted value. \"\"\" prediction: int generate_token(to_encode) Generate a JWT token. Parameters: to_encode ( str ) \u2013 The string to encode in the token. Returns: str \u2013 The generated JWT token. Source code in api/utils.py def generate_token(to_encode): \"\"\" Generate a JWT token. Args: to_encode (str): The string to encode in the token. Returns: str: The generated JWT token. \"\"\" load_dotenv() SECRET_KEY = os.environ.get(\"SECRET_KEY\") ALGORITHM = \"HS256\" to_encode_dict = {\"sub\": to_encode} encoded_jwt = jwt.encode(to_encode_dict, SECRET_KEY, algorithm=ALGORITHM) return encoded_jwt get_model(run_name) Load a model from a pickle file. Parameters: run_name ( str ) \u2013 The name of the model run. Returns: \u2013 The loaded model. Source code in api/utils.py def get_model(run_name): \"\"\" Load a model from a pickle file. Args: run_name (str): The name of the model run. Returns: The loaded model. \"\"\" with open(f\"api/{run_name}.pkl\", 'rb') as file: loaded_model = pickle.load(file) return loaded_model has_access(credentials=Depends(HTTPBearer())) async Validates the access token provided in the request headers. Parameters: credentials ( HTTPAuthorizationCredentials , default: Depends ( HTTPBearer ()) ) \u2013 The bearer token credentials. Returns: bool \u2013 True if the user has access, otherwise raises HTTPException. Raises: HTTPException \u2013 If the token is invalid or the user is not authorized. Source code in api/utils.py async def has_access(credentials: HTTPAuthorizationCredentials = Depends(HTTPBearer())): \"\"\" Validates the access token provided in the request headers. Args: credentials (HTTPAuthorizationCredentials): The bearer token credentials. Returns: bool: True if the user has access, otherwise raises HTTPException. Raises: HTTPException: If the token is invalid or the user is not authorized. \"\"\" token = credentials.credentials load_dotenv() SECRET_KEY = os.environ.get(\"SECRET_KEY\") ALGORITHM = \"HS256\" credentials_exception = HTTPException( status_code=status.HTTP_401_UNAUTHORIZED, detail=\"Could not validate credentials\", headers={\"WWW-Authenticate\": \"Bearer\"}, ) try: payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM]) username: str = payload.get(\"sub\") except JWTError: raise credentials_exception if username == \"admin\": return True else: raise credentials_exception predict_single(loaded_model, order) Make a prediction using the loaded model and the input order. Parameters: loaded_model \u2013 The pre-trained model. order ( SinglePredictionInput ) \u2013 The input data for making the prediction. Returns: int \u2013 The predicted value. Source code in api/utils.py def predict_single(loaded_model, order): \"\"\" Make a prediction using the loaded model and the input order. Args: loaded_model: The pre-trained model. order (SinglePredictionInput): The input data for making the prediction. Returns: int: The predicted value. \"\"\" data = {'produit_recu': [order.produit_recu], 'temps_livraison': [order.temps_livraison]} df_to_predict = pd.DataFrame(data) prediction = loaded_model.predict(df_to_predict) return prediction[0]","title":"Utils"},{"location":"api/utils/#api.utils.SinglePredictionInput","text":"Bases: BaseModel Model for single prediction input. Attributes: produit_recu ( int ) \u2013 The quantity of the received product. temps_livraison ( int ) \u2013 The delivery time. Source code in api/utils.py class SinglePredictionInput(BaseModel): \"\"\" Model for single prediction input. Attributes: produit_recu (int): The quantity of the received product. temps_livraison (int): The delivery time. \"\"\" produit_recu: int temps_livraison: int","title":"SinglePredictionInput"},{"location":"api/utils/#api.utils.SinglePredictionOutput","text":"Bases: BaseModel Model for single prediction output. Attributes: prediction ( int ) \u2013 The predicted value. Source code in api/utils.py class SinglePredictionOutput(BaseModel): \"\"\" Model for single prediction output. Attributes: prediction (int): The predicted value. \"\"\" prediction: int","title":"SinglePredictionOutput"},{"location":"api/utils/#api.utils.generate_token","text":"Generate a JWT token. Parameters: to_encode ( str ) \u2013 The string to encode in the token. Returns: str \u2013 The generated JWT token. Source code in api/utils.py def generate_token(to_encode): \"\"\" Generate a JWT token. Args: to_encode (str): The string to encode in the token. Returns: str: The generated JWT token. \"\"\" load_dotenv() SECRET_KEY = os.environ.get(\"SECRET_KEY\") ALGORITHM = \"HS256\" to_encode_dict = {\"sub\": to_encode} encoded_jwt = jwt.encode(to_encode_dict, SECRET_KEY, algorithm=ALGORITHM) return encoded_jwt","title":"generate_token"},{"location":"api/utils/#api.utils.get_model","text":"Load a model from a pickle file. Parameters: run_name ( str ) \u2013 The name of the model run. Returns: \u2013 The loaded model. Source code in api/utils.py def get_model(run_name): \"\"\" Load a model from a pickle file. Args: run_name (str): The name of the model run. Returns: The loaded model. \"\"\" with open(f\"api/{run_name}.pkl\", 'rb') as file: loaded_model = pickle.load(file) return loaded_model","title":"get_model"},{"location":"api/utils/#api.utils.has_access","text":"Validates the access token provided in the request headers. Parameters: credentials ( HTTPAuthorizationCredentials , default: Depends ( HTTPBearer ()) ) \u2013 The bearer token credentials. Returns: bool \u2013 True if the user has access, otherwise raises HTTPException. Raises: HTTPException \u2013 If the token is invalid or the user is not authorized. Source code in api/utils.py async def has_access(credentials: HTTPAuthorizationCredentials = Depends(HTTPBearer())): \"\"\" Validates the access token provided in the request headers. Args: credentials (HTTPAuthorizationCredentials): The bearer token credentials. Returns: bool: True if the user has access, otherwise raises HTTPException. Raises: HTTPException: If the token is invalid or the user is not authorized. \"\"\" token = credentials.credentials load_dotenv() SECRET_KEY = os.environ.get(\"SECRET_KEY\") ALGORITHM = \"HS256\" credentials_exception = HTTPException( status_code=status.HTTP_401_UNAUTHORIZED, detail=\"Could not validate credentials\", headers={\"WWW-Authenticate\": \"Bearer\"}, ) try: payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM]) username: str = payload.get(\"sub\") except JWTError: raise credentials_exception if username == \"admin\": return True else: raise credentials_exception","title":"has_access"},{"location":"api/utils/#api.utils.predict_single","text":"Make a prediction using the loaded model and the input order. Parameters: loaded_model \u2013 The pre-trained model. order ( SinglePredictionInput ) \u2013 The input data for making the prediction. Returns: int \u2013 The predicted value. Source code in api/utils.py def predict_single(loaded_model, order): \"\"\" Make a prediction using the loaded model and the input order. Args: loaded_model: The pre-trained model. order (SinglePredictionInput): The input data for making the prediction. Returns: int: The predicted value. \"\"\" data = {'produit_recu': [order.produit_recu], 'temps_livraison': [order.temps_livraison]} df_to_predict = pd.DataFrame(data) prediction = loaded_model.predict(df_to_predict) return prediction[0]","title":"predict_single"},{"location":"mkdocs/tutorial/","text":"Utilisation de mkdocs I Cr\u00e9er la documentation 1. Installer les librairies pythons mkdocs, mkdocstrings et mkdocstrings-python 2. Cr\u00e9er un fichier mkdocs.yml \u00e0 la racine du projet pour configurer la doc site_name: \"Nom de votre projet\" nav: # on d\u00e9finit l'architecture de la doc en faisant les liens vers les fichiers dans docs - Accueil: index.md - Documentation: - Introduction: introduction.md - API: - Module1: api/module1.md - Module2: api/module2.md theme: name: readthedocs #on peut utiliser d'autre theme de doc plugins: - search - mkdocstrings: #ce la permet d'int\u00e9grer directement les docstrings handlers: python: options: docstring_style: google rendering: show_source: true 3. Cr\u00e9er le dossier docs et ajouter toutes les docs 4. On peut inclure directement les docstings comme cela # Documentation du Module1 ::: src.module1 handler: python rendering: show_source: true 5. Pour ajouter des fichiers md en dehors du r\u00e9pertoire docs, il faut cr\u00e9er des liens symboliques dans docs: Cr\u00e9ation des liens symboliques : Supposons que vous ayez un fichier Markdown situ\u00e9 dans ../external_docs/intro.md que vous voulez inclure dans la documentation. Cr\u00e9ez un lien symbolique dans le r\u00e9pertoire docs : ln -s ../external_docs/intro.md docs/intro.md Cette commande cr\u00e9e un lien symbolique nomm\u00e9 intro.md dans le r\u00e9pertoire docs pointant vers ../external_docs/intro.md. II Publier la documentation sur github pages 1. En local cr\u00e9er la branche qui va accueillir la doc (le html et css g\u00e9n\u00e9r\u00e9s automatiquement notamment) bash git branch -M gh-pages git push -f origin gh-pages 2. Configurer GitHub Pages Acc\u00e9dez \u00e0 votre d\u00e9p\u00f4t sur GitHub. Allez dans \"Settings\". Dans la section \"Pages\", s\u00e9lectionnez la branche gh-pages comme source et roots Cliquez sur \"Save\". 3. Construisez votre doc et d\u00e9ployer votre code sur la branch: bash mkdocs build mkdocs gh-deploy --force","title":"Mkdocs tutorial (French)"},{"location":"mkdocs/tutorial/#utilisation-de-mkdocs","text":"","title":"Utilisation de mkdocs"},{"location":"mkdocs/tutorial/#i-creer-la-documentation","text":"","title":"I Cr\u00e9er la documentation"},{"location":"mkdocs/tutorial/#1-installer-les-librairies-pythons-mkdocs-mkdocstrings-et-mkdocstrings-python","text":"","title":"1. Installer les librairies pythons mkdocs, mkdocstrings et mkdocstrings-python"},{"location":"mkdocs/tutorial/#2-creer-un-fichier-mkdocsyml-a-la-racine-du-projet-pour-configurer-la-doc","text":"site_name: \"Nom de votre projet\" nav: # on d\u00e9finit l'architecture de la doc en faisant les liens vers les fichiers dans docs - Accueil: index.md - Documentation: - Introduction: introduction.md - API: - Module1: api/module1.md - Module2: api/module2.md theme: name: readthedocs #on peut utiliser d'autre theme de doc plugins: - search - mkdocstrings: #ce la permet d'int\u00e9grer directement les docstrings handlers: python: options: docstring_style: google rendering: show_source: true","title":"2. Cr\u00e9er un fichier mkdocs.yml \u00e0 la racine du projet pour configurer la doc"},{"location":"mkdocs/tutorial/#3-creer-le-dossier-docs-et-ajouter-toutes-les-docs","text":"","title":"3. Cr\u00e9er le dossier docs et ajouter toutes les docs"},{"location":"mkdocs/tutorial/#4-on-peut-inclure-directement-les-docstings-comme-cela","text":"# Documentation du Module1 ::: src.module1 handler: python rendering: show_source: true","title":"4. On peut inclure directement les docstings comme cela"},{"location":"mkdocs/tutorial/#5-pour-ajouter-des-fichiers-md-en-dehors-du-repertoire-docs-il-faut-creer-des-liens-symboliques-dans-docs","text":"","title":"5. Pour ajouter des fichiers md en dehors du r\u00e9pertoire docs, il faut cr\u00e9er des liens symboliques dans docs:"},{"location":"mkdocs/tutorial/#creation-des-liens-symboliques","text":"Supposons que vous ayez un fichier Markdown situ\u00e9 dans ../external_docs/intro.md que vous voulez inclure dans la documentation. Cr\u00e9ez un lien symbolique dans le r\u00e9pertoire docs : ln -s ../external_docs/intro.md docs/intro.md Cette commande cr\u00e9e un lien symbolique nomm\u00e9 intro.md dans le r\u00e9pertoire docs pointant vers ../external_docs/intro.md.","title":"Cr\u00e9ation des liens symboliques :"},{"location":"mkdocs/tutorial/#ii-publier-la-documentation-sur-github-pages","text":"","title":"II Publier la documentation sur github pages"},{"location":"mkdocs/tutorial/#1-en-local-creer-la-branche-qui-va-accueillir-la-doc-le-html-et-css-generes-automatiquement-notamment","text":"bash git branch -M gh-pages git push -f origin gh-pages","title":"1. En local cr\u00e9er la branche qui va accueillir la doc (le html et css g\u00e9n\u00e9r\u00e9s automatiquement notamment)"},{"location":"mkdocs/tutorial/#2-configurer-github-pages","text":"Acc\u00e9dez \u00e0 votre d\u00e9p\u00f4t sur GitHub. Allez dans \"Settings\". Dans la section \"Pages\", s\u00e9lectionnez la branche gh-pages comme source et roots Cliquez sur \"Save\".","title":"2. Configurer GitHub Pages"},{"location":"mkdocs/tutorial/#3-construisez-votre-doc-et-deployer-votre-code-sur-la-branch","text":"bash mkdocs build mkdocs gh-deploy --force","title":"3. Construisez votre doc et d\u00e9ployer votre code sur la branch:"}]}